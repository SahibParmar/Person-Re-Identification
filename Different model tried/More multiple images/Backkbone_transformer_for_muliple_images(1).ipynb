{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Similar means 1"
      ],
      "metadata": {
        "id": "VfxcxcUbQ0jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydX4j1eeGPQO",
        "outputId": "c2fb62ed-e39a-4aab-f237-a1ef6ae9fe86"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "priyanagda_cuhk03_path = kagglehub.dataset_download('priyanagda/cuhk03')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlwT-4YlwN04",
        "outputId": "3be92fa4-3ea8-4de8-988a-fc0e302503c5"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/priyanagda/cuhk03?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.69G/2.69G [01:32<00:00, 31.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "tuples=[]\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "'''/root/.cache/kagglehub/datasets/priyanagda/cuhk03/versions/3/archive/images_labeled/1_313_2_09.png\n",
        "'''\n",
        "for dirname, _, filenames in os.walk(priyanagda_cuhk03_path):\n",
        "    for filename in filenames:\n",
        "\n",
        "      if dirname[-14:]=='images_labeled':\n",
        "        datapoint=[filename[0:5],filename[6],os.path.join(dirname, filename)]\n",
        "        tuples.append(datapoint)\n",
        "\n",
        "data=pd.DataFrame(tuples,columns=['id','Orientation','path'])\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ue5HT1usxW0Y",
        "outputId": "60afde8b-19b0-49b3-d389-3cf9679d9a7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id Orientation                                               path\n",
              "0      1_469           1  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "1      2_023           2  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "2      1_833           1  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "3      2_211           1  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "4      3_034           2  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "...      ...         ...                                                ...\n",
              "14091  1_155           1  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "14092  2_268           2  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "14093  2_328           2  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "14094  1_644           1  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "14095  1_664           2  /root/.cache/kagglehub/datasets/priyanagda/cuh...\n",
              "\n",
              "[14096 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c49ccdc0-76b8-4a98-ac7e-427ccc068108\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Orientation</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_469</td>\n",
              "      <td>1</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2_023</td>\n",
              "      <td>2</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_833</td>\n",
              "      <td>1</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2_211</td>\n",
              "      <td>1</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3_034</td>\n",
              "      <td>2</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14091</th>\n",
              "      <td>1_155</td>\n",
              "      <td>1</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14092</th>\n",
              "      <td>2_268</td>\n",
              "      <td>2</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14093</th>\n",
              "      <td>2_328</td>\n",
              "      <td>2</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14094</th>\n",
              "      <td>1_644</td>\n",
              "      <td>1</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14095</th>\n",
              "      <td>1_664</td>\n",
              "      <td>2</td>\n",
              "      <td>/root/.cache/kagglehub/datasets/priyanagda/cuh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14096 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c49ccdc0-76b8-4a98-ac7e-427ccc068108')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c49ccdc0-76b8-4a98-ac7e-427ccc068108 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c49ccdc0-76b8-4a98-ac7e-427ccc068108');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5bc4e584-c4b3-4d82-a415-7fd64ed8bd8e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5bc4e584-c4b3-4d82-a415-7fd64ed8bd8e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5bc4e584-c4b3-4d82-a415-7fd64ed8bd8e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_96913b53-fee1-4b3e-83e0-6a3cc9e1bb24\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_96913b53-fee1-4b3e-83e0-6a3cc9e1bb24 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 14096,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1467,\n        \"samples\": [\n          \"2_195\",\n          \"1_599\",\n          \"1_109\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Orientation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14096,\n        \"samples\": [\n          \"/root/.cache/kagglehub/datasets/priyanagda/cuhk03/versions/3/archive/images_labeled/2_192_2_07.png\",\n          \"/root/.cache/kagglehub/datasets/priyanagda/cuhk03/versions/3/archive/images_labeled/1_037_2_09.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in enumerate(list(data['id'])):\n",
        "  if j[0]=='1' and j[2:5]=='001':\n",
        "    path1=list(data['path'])[i]\n",
        "    break\n",
        "for i,j in enumerate(list(data['id'])):\n",
        "  if j[0]=='2' and j[2:5]=='001':\n",
        "    path2=list(data['path'])[i]\n",
        "    break\n",
        "print(path1,path2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXkn3bfnaB0s",
        "outputId": "5e6119f9-3cc0-4ab8-e025-652d21dbb14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/priyanagda/cuhk03/versions/3/archive/images_labeled/1_001_2_06.png /root/.cache/kagglehub/datasets/priyanagda/cuhk03/versions/3/archive/images_labeled/2_001_1_05.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(path1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "Z7_NHC7ubyH-",
        "outputId": "4dc993eb-24b0-4d53-8031-5f9655097dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing Data"
      ],
      "metadata": {
        "id": "ukgngIKycjj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# for each identity: Choose random k, sample k images of same identity and add into persons list\n",
        "# and id into ids list\n",
        "persons=[]\n",
        "ids=[]\n",
        "\n",
        "unique_ids = data['id'].unique()  # Get unique identities\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "for identity in unique_ids:\n",
        "    # Filter data for the current identity\n",
        "    identity_data = data[data['id'] == identity]\n",
        "\n",
        "# Creating Positive pairs(Similar i.e. y=1)\n",
        "    for _ in range(5):\n",
        "      k1 = random.randint(1, 10)\n",
        "      k2 = random.randint(1, 10)\n",
        "      while k1>7 and k2>7 and k1-k2<=1:\n",
        "        k1 = random.randint(1, 10)\n",
        "        k2 = random.randint(1, 10)\n",
        "      # Sample k images if available, otherwise sample all\n",
        "      num_samples = min(k1, len(identity_data))\n",
        "      sampled_data1 = identity_data.sample(n=num_samples)\n",
        "      # Sample k images if available, otherwise sample all\n",
        "      num_samples = min(k2, len(identity_data))\n",
        "      sampled_data2 = identity_data.sample(n=num_samples)\n",
        "\n",
        "      X_train.append([sampled_data1,sampled_data2])\n",
        "      y_train.append(1)\n",
        "# Creating Negative pairs(Dissimilar i.e. y=0)\n",
        "    for _ in range(7):\n",
        "      different_identity = np.random.choice(unique_ids)\n",
        "      while different_identity == identity:\n",
        "        different_identity = np.random.choice(unique_ids)\n",
        "      different_data = data[data['id'] == different_identity]\n",
        "\n",
        "      k1 = random.randint(1, 10)\n",
        "      k2 = random.randint(1, 10)\n",
        "      while k1>7 and k2>7 and k1-k2<=1:\n",
        "        k1 = random.randint(1, 10)\n",
        "        k2 = random.randint(1, 10)\n",
        "      # Sample k images if available, otherwise sample all\n",
        "      num_samples = min(k1, len(identity_data))\n",
        "      sampled_data1 = identity_data.sample(n=num_samples)\n",
        "      # Sample k images if available, otherwise sample all\n",
        "      num_samples = min(k2, len(different_data))\n",
        "      sampled_data2 = different_data.sample(n=num_samples)\n",
        "\n",
        "      X_train.append([sampled_data1,sampled_data2])\n",
        "      y_train.append(0)\n",
        "\n",
        "len(X_train),len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Em7eBtDcl1x",
        "outputId": "24175b82-cfb4-4b88-ac37-61efca4a3a64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17604, 17604)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=3\n",
        "len(X_train[idx][0]),len(X_train[idx][1]),y_train[idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kJMDOO495_i",
        "outputId": "f321f554-b5a9-40c8-ac8e-004e1f47de8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 5, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Code"
      ],
      "metadata": {
        "id": "iNwvUCphcncH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install clip\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiFeSR-8xIHQ",
        "outputId": "1f4600f8-9d2f-467c-87ba-79c309331e1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-epc4cs13\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-epc4cs13\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=76f6a751e6bccb985c57aa7f69b5512d706e4f222bd626cfda01b149a06313d2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n1jyb3r_/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n",
            "Requirement already satisfied: clip in /usr/local/lib/python3.10/dist-packages (1.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip) (3.0.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt,image as mpimg\n",
        "from torch.optim import Adam\n",
        "from torchvision import transforms as transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader,random_split\n",
        "import torch.optim as optim\n",
        "# from torchvision.models.resnet import Bottleneck\n",
        "from PIL import Image\n",
        "import clip\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt,image as mpimg #Make sure you have imported the necessary modules\n",
        "\n",
        "def display_image(image_path):\n",
        "    \"\"\"\n",
        "    Displays an image using matplotlib.\n",
        "\n",
        "    Args:\n",
        "      image_path: Path to the image file.\n",
        "    \"\"\"\n",
        "    img = mpimg.imread(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off') # Hide axes\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "r24qUzbMwdcV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiCVkLJ_wsg3",
        "outputId": "5c52cda1-6565-4e32-b88d-8feb3465055d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model, transform = clip.load(\"ViT-B/16\",device=device)"
      ],
      "metadata": {
        "id": "cvzAWSfizB-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c50a30b-6a08-45c5-e104-835087f3f104"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 335M/335M [00:06<00:00, 57.3MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, X, Y, transform=None):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_set1 = []\n",
        "        img_set2 = []\n",
        "# X[idx][1] has  sampled tuples from a dataframe\n",
        "        for i in self.X[idx][0]['path'].values:\n",
        "          temp=Image.open(i).convert('RGB')\n",
        "          if self.transform:\n",
        "            temp=self.transform(temp)\n",
        "          img_set1.append(temp)\n",
        "        for i in self.X[idx][1]['path'].values:\n",
        "          temp=Image.open(i).convert('RGB')\n",
        "          if self.transform:\n",
        "            temp=self.transform(temp)\n",
        "          img_set2.append(temp)\n",
        "\n",
        "\n",
        "        label = self.Y[idx]\n",
        "        label = torch.tensor(label, dtype=torch.float32)\n",
        "        return img_set1,img_set2, label\n",
        "\n",
        "\n",
        "train_data=SiameseDataset(X_train,y_train,transform=transform)"
      ],
      "metadata": {
        "id": "6MibVxJHBBP9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "point=train_data[0]\n",
        "len(point[0]),len(point[1]),point[0][0].shape,point[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H1wt1K4ZPIG",
        "outputId": "326677c8-9bd2-4317-c1d0-d46cf5e33239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 7, torch.Size([3, 224, 224]), tensor(1.))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def siamese_collate_fn(batch):\n",
        "    img_set1, img_set2, labels = zip(*batch)  # Unzip the batch\n",
        "\n",
        "    # Stack and pad the sequences in each batch\n",
        "    padded_img_set1 = pad_sequence([torch.stack(imgs) for imgs in img_set1], batch_first=True)  # Shape: (batch_size, max_len_set1, C, H, W)\n",
        "    padded_img_set2 = pad_sequence([torch.stack(imgs) for imgs in img_set2], batch_first=True)  # Shape: (batch_size, max_len_set2, C, H, W)\n",
        "\n",
        "    # Create attention masks: 1 for real data, 0 for padding\n",
        "    mask_set1 = torch.tensor([[1] * len(imgs) + [0] * (padded_img_set1.size(1) - len(imgs)) for imgs in img_set1], dtype=torch.bool)\n",
        "    mask_set2 = torch.tensor([[1] * len(imgs) + [0] * (padded_img_set2.size(1) - len(imgs)) for imgs in img_set2], dtype=torch.bool)\n",
        "\n",
        "    labels = torch.tensor(labels, dtype=torch.float32)  # Stack labels\n",
        "\n",
        "    return padded_img_set1, padded_img_set2, mask_set1, mask_set2, labels\n"
      ],
      "metadata": {
        "id": "I9bovRi8aOLK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, collate_fn=siamese_collate_fn, shuffle=True)"
      ],
      "metadata": {
        "id": "dSsoAiied1BE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3vExm4br-FA",
        "outputId": "d68358e5-c1d1-4bf7-c65c-d81d6beb22bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "551"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Architectural Part**"
      ],
      "metadata": {
        "id": "FXMMlmspygLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Contrastive_loss_fn(nn.Module):\n",
        "    def __init__(self, margin):\n",
        "        super(Contrastive_loss_fn, self).__init__()\n",
        "        self.margin = torch.tensor(margin, device='cuda')\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        cosine_sim = F.cosine_similarity(output1, output2)\n",
        "        cosine_dist = 1.0-cosine_sim\n",
        "        loss_contrastive = torch.mean((label) * torch.pow(cosine_dist, 2) +\n",
        "                                      (1 - label) * torch.pow(torch.clamp(self.margin - cosine_dist, min=0.0), 2))\n",
        "        return loss_contrastive"
      ],
      "metadata": {
        "id": "SXot9uCbyf6n"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Backbone Class (same as your original SiameseNetwork without Siamese functionality)\n",
        "class BackboneNetwork(nn.Module):\n",
        "    def __init__(self, emb_dim, model):\n",
        "        super(BackboneNetwork, self).__init__()\n",
        "        self.encoder_model = model\n",
        "        self.classifier = nn.Linear(in_features=512, out_features=emb_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def encode_one_image(self, x):\n",
        "        x = self.encoder_model.encode_image(x)\n",
        "        x = self.classifier(x.float())\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encode_one_image(x)\n",
        "\n",
        "# Initialize the backbone with pretrained weights\n",
        "emb_dim = 1024\n",
        "\n",
        "#model was initially the clip model\n",
        "backbone = BackboneNetwork(emb_dim=emb_dim, model=base_model)\n",
        "\n",
        "\n",
        "model_path='/content/drive/MyDrive/Person ReIdentification/clip_transformer_model_parameters.pth'\n",
        "# Load the pretrained weights (assumes you have saved the weights as \"backbone_weights.pth\")\n",
        "backbone.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
        "print(\"Backbone loaded with pretrained weights.\")\n",
        "\n",
        "# freezing the backbone\n",
        "for param in backbone.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0QsFzqfXmJRG",
        "outputId": "505a352a-8272-43ab-9813-7df3ffa96966"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-e45ab9f00f3d>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  backbone.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for BackboneNetwork:\n\tMissing key(s) in state_dict: \"encoder_model.positional_embedding\", \"encoder_model.text_projection\", \"encoder_model.logit_scale\", \"encoder_model.visual.class_embedding\", \"encoder_model.visual.positional_embedding\", \"encoder_model.visual.proj\", \"encoder_model.visual.conv1.weight\", \"encoder_model.visual.ln_pre.weight\", \"encoder_model.visual.ln_pre.bias\", \"encoder_model.visual.transformer.resblocks.0.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.0.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.0.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.0.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.0.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.0.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.0.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.0.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.0.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.0.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.0.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.0.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.1.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.1.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.1.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.1.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.1.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.1.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.1.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.1.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.1.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.1.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.1.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.1.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.2.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.2.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.2.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.2.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.2.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.2.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.2.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.2.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.2.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.2.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.2.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.2.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.3.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.3.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.3.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.3.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.3.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.3.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.3.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.3.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.3.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.3.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.3.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.3.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.4.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.4.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.4.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.4.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.4.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.4.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.4.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.4.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.4.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.4.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.4.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.4.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.5.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.5.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.5.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.5.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.5.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.5.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.5.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.5.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.5.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.5.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.5.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.5.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.6.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.6.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.6.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.6.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.6.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.6.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.6.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.6.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.6.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.6.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.6.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.6.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.7.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.7.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.7.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.7.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.7.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.7.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.7.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.7.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.7.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.7.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.7.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.7.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.8.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.8.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.8.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.8.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.8.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.8.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.8.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.8.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.8.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.8.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.8.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.8.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.9.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.9.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.9.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.9.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.9.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.9.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.9.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.9.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.9.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.9.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.9.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.9.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.10.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.10.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.10.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.10.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.10.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.10.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.10.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.10.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.10.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.10.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.10.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.10.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.11.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.11.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.11.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.11.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.11.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.11.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.11.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.11.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.11.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.11.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.11.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.11.ln_2.bias\", \"encoder_model.visual.ln_post.weight\", \"encoder_model.visual.ln_post.bias\", \"encoder_model.transformer.resblocks.0.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.0.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.0.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.0.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.0.ln_1.weight\", \"encoder_model.transformer.resblocks.0.ln_1.bias\", \"encoder_model.transformer.resblocks.0.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.0.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.0.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.0.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.0.ln_2.weight\", \"encoder_model.transformer.resblocks.0.ln_2.bias\", \"encoder_model.transformer.resblocks.1.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.1.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.1.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.1.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.1.ln_1.weight\", \"encoder_model.transformer.resblocks.1.ln_1.bias\", \"encoder_model.transformer.resblocks.1.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.1.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.1.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.1.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.1.ln_2.weight\", \"encoder_model.transformer.resblocks.1.ln_2.bias\", \"encoder_model.transformer.resblocks.2.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.2.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.2.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.2.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.2.ln_1.weight\", \"encoder_model.transformer.resblocks.2.ln_1.bias\", \"encoder_model.transformer.resblocks.2.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.2.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.2.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.2.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.2.ln_2.weight\", \"encoder_model.transformer.resblocks.2.ln_2.bias\", \"encoder_model.transformer.resblocks.3.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.3.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.3.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.3.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.3.ln_1.weight\", \"encoder_model.transformer.resblocks.3.ln_1.bias\", \"encoder_model.transformer.resblocks.3.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.3.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.3.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.3.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.3.ln_2.weight\", \"encoder_model.transformer.resblocks.3.ln_2.bias\", \"encoder_model.transformer.resblocks.4.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.4.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.4.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.4.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.4.ln_1.weight\", \"encoder_model.transformer.resblocks.4.ln_1.bias\", \"encoder_model.transformer.resblocks.4.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.4.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.4.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.4.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.4.ln_2.weight\", \"encoder_model.transformer.resblocks.4.ln_2.bias\", \"encoder_model.transformer.resblocks.5.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.5.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.5.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.5.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.5.ln_1.weight\", \"encoder_model.transformer.resblocks.5.ln_1.bias\", \"encoder_model.transformer.resblocks.5.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.5.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.5.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.5.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.5.ln_2.weight\", \"encoder_model.transformer.resblocks.5.ln_2.bias\", \"encoder_model.transformer.resblocks.6.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.6.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.6.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.6.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.6.ln_1.weight\", \"encoder_model.transformer.resblocks.6.ln_1.bias\", \"encoder_model.transformer.resblocks.6.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.6.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.6.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.6.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.6.ln_2.weight\", \"encoder_model.transformer.resblocks.6.ln_2.bias\", \"encoder_model.transformer.resblocks.7.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.7.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.7.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.7.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.7.ln_1.weight\", \"encoder_model.transformer.resblocks.7.ln_1.bias\", \"encoder_model.transformer.resblocks.7.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.7.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.7.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.7.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.7.ln_2.weight\", \"encoder_model.transformer.resblocks.7.ln_2.bias\", \"encoder_model.transformer.resblocks.8.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.8.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.8.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.8.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.8.ln_1.weight\", \"encoder_model.transformer.resblocks.8.ln_1.bias\", \"encoder_model.transformer.resblocks.8.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.8.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.8.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.8.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.8.ln_2.weight\", \"encoder_model.transformer.resblocks.8.ln_2.bias\", \"encoder_model.transformer.resblocks.9.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.9.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.9.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.9.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.9.ln_1.weight\", \"encoder_model.transformer.resblocks.9.ln_1.bias\", \"encoder_model.transformer.resblocks.9.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.9.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.9.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.9.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.9.ln_2.weight\", \"encoder_model.transformer.resblocks.9.ln_2.bias\", \"encoder_model.transformer.resblocks.10.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.10.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.10.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.10.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.10.ln_1.weight\", \"encoder_model.transformer.resblocks.10.ln_1.bias\", \"encoder_model.transformer.resblocks.10.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.10.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.10.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.10.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.10.ln_2.weight\", \"encoder_model.transformer.resblocks.10.ln_2.bias\", \"encoder_model.transformer.resblocks.11.attn.in_proj_weight\", \"encoder_model.transformer.resblocks.11.attn.in_proj_bias\", \"encoder_model.transformer.resblocks.11.attn.out_proj.weight\", \"encoder_model.transformer.resblocks.11.attn.out_proj.bias\", \"encoder_model.transformer.resblocks.11.ln_1.weight\", \"encoder_model.transformer.resblocks.11.ln_1.bias\", \"encoder_model.transformer.resblocks.11.mlp.c_fc.weight\", \"encoder_model.transformer.resblocks.11.mlp.c_fc.bias\", \"encoder_model.transformer.resblocks.11.mlp.c_proj.weight\", \"encoder_model.transformer.resblocks.11.mlp.c_proj.bias\", \"encoder_model.transformer.resblocks.11.ln_2.weight\", \"encoder_model.transformer.resblocks.11.ln_2.bias\", \"encoder_model.token_embedding.weight\", \"encoder_model.ln_final.weight\", \"encoder_model.ln_final.bias\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"backbone.encoder_model.positional_embedding\", \"backbone.encoder_model.text_projection\", \"backbone.encoder_model.logit_scale\", \"backbone.encoder_model.visual.class_embedding\", \"backbone.encoder_model.visual.positional_embedding\", \"backbone.encoder_model.visual.proj\", \"backbone.encoder_model.visual.conv1.weight\", \"backbone.encoder_model.visual.ln_pre.weight\", \"backbone.encoder_model.visual.ln_pre.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.1.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.1.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.1.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.1.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.1.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.1.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.1.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.1.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.1.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.1.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.1.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.1.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.2.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.2.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.2.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.2.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.2.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.2.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.2.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.2.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.2.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.2.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.2.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.2.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.3.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.3.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.3.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.3.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.3.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.3.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.3.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.3.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.3.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.3.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.3.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.3.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.4.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.4.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.4.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.4.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.4.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.4.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.4.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.4.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.4.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.4.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.4.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.4.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.5.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.5.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.5.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.5.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.5.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.5.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.5.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.5.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.5.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.5.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.5.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.5.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.6.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.6.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.6.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.6.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.6.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.6.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.6.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.6.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.6.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.6.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.6.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.6.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.7.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.7.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.7.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.7.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.7.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.7.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.7.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.7.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.7.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.7.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.7.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.7.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.8.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.8.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.8.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.8.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.8.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.8.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.8.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.8.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.8.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.8.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.8.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.8.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.9.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.9.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.9.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.9.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.9.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.9.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.9.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.9.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.9.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.9.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.9.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.9.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.10.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.10.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.10.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.10.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.10.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.10.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.10.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.10.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.10.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.10.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.10.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.10.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.11.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.11.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.11.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.11.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.11.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.11.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.11.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.11.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.11.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.11.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.11.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.11.ln_2.bias\", \"backbone.encoder_model.visual.ln_post.weight\", \"backbone.encoder_model.visual.ln_post.bias\", \"backbone.encoder_model.transformer.resblocks.0.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.0.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.0.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.0.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.0.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.0.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.0.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.0.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.0.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.0.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.0.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.0.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.1.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.1.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.1.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.1.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.1.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.1.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.1.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.1.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.1.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.1.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.1.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.1.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.2.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.2.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.2.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.2.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.2.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.2.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.2.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.2.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.2.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.2.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.2.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.2.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.3.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.3.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.3.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.3.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.3.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.3.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.3.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.3.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.3.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.3.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.3.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.3.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.4.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.4.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.4.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.4.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.4.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.4.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.4.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.4.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.4.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.4.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.4.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.4.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.5.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.5.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.5.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.5.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.5.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.5.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.5.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.5.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.5.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.5.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.5.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.5.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.6.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.6.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.6.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.6.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.6.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.6.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.6.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.6.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.6.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.6.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.6.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.6.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.7.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.7.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.7.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.7.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.7.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.7.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.7.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.7.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.7.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.7.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.7.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.7.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.8.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.8.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.8.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.8.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.8.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.8.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.8.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.8.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.8.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.8.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.8.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.8.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.9.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.9.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.9.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.9.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.9.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.9.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.9.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.9.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.9.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.9.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.9.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.9.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.10.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.10.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.10.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.10.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.10.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.10.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.10.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.10.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.10.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.10.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.10.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.10.ln_2.bias\", \"backbone.encoder_model.transformer.resblocks.11.attn.in_proj_weight\", \"backbone.encoder_model.transformer.resblocks.11.attn.in_proj_bias\", \"backbone.encoder_model.transformer.resblocks.11.attn.out_proj.weight\", \"backbone.encoder_model.transformer.resblocks.11.attn.out_proj.bias\", \"backbone.encoder_model.transformer.resblocks.11.ln_1.weight\", \"backbone.encoder_model.transformer.resblocks.11.ln_1.bias\", \"backbone.encoder_model.transformer.resblocks.11.mlp.c_fc.weight\", \"backbone.encoder_model.transformer.resblocks.11.mlp.c_fc.bias\", \"backbone.encoder_model.transformer.resblocks.11.mlp.c_proj.weight\", \"backbone.encoder_model.transformer.resblocks.11.mlp.c_proj.bias\", \"backbone.encoder_model.transformer.resblocks.11.ln_2.weight\", \"backbone.encoder_model.transformer.resblocks.11.ln_2.bias\", \"backbone.encoder_model.token_embedding.weight\", \"backbone.encoder_model.ln_final.weight\", \"backbone.encoder_model.ln_final.bias\", \"backbone.classifier.weight\", \"backbone.classifier.bias\", \"transformer_encoder.layers.0.self_attn.in_proj_weight\", \"transformer_encoder.layers.0.self_attn.in_proj_bias\", \"transformer_encoder.layers.0.self_attn.out_proj.weight\", \"transformer_encoder.layers.0.self_attn.out_proj.bias\", \"transformer_encoder.layers.0.linear1.weight\", \"transformer_encoder.layers.0.linear1.bias\", \"transformer_encoder.layers.0.linear2.weight\", \"transformer_encoder.layers.0.linear2.bias\", \"transformer_encoder.layers.0.norm1.weight\", \"transformer_encoder.layers.0.norm1.bias\", \"transformer_encoder.layers.0.norm2.weight\", \"transformer_encoder.layers.0.norm2.bias\", \"transformer_encoder.layers.1.self_attn.in_proj_weight\", \"transformer_encoder.layers.1.self_attn.in_proj_bias\", \"transformer_encoder.layers.1.self_attn.out_proj.weight\", \"transformer_encoder.layers.1.self_attn.out_proj.bias\", \"transformer_encoder.layers.1.linear1.weight\", \"transformer_encoder.layers.1.linear1.bias\", \"transformer_encoder.layers.1.linear2.weight\", \"transformer_encoder.layers.1.linear2.bias\", \"transformer_encoder.layers.1.norm1.weight\", \"transformer_encoder.layers.1.norm1.bias\", \"transformer_encoder.layers.1.norm2.weight\", \"transformer_encoder.layers.1.norm2.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e45ab9f00f3d>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Person ReIdentification/clip_transformer_model_parameters.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Load the pretrained weights (assumes you have saved the weights as \"backbone_weights.pth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Backbone loaded with pretrained weights.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BackboneNetwork:\n\tMissing key(s) in state_dict: \"encoder_model.positional_embedding\", \"encoder_model.text_projection\", \"encoder_model.logit_scale\", \"encoder_model.visual.class_embedding\", \"encoder_model.visual.positional_embedding\", \"encoder_model.visual.proj\", \"encoder_model.visual.conv1.weight\", \"encoder_model.visual.ln_pre.weight\", \"encoder_model.visual.ln_pre.bias\", \"encoder_model.visual.transformer.resblocks.0.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.0.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.0.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.0.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.0.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.0.ln_1.bias\", \"encoder_model.visual.transformer.resblocks.0.mlp.c_fc.weight\", \"encoder_model.visual.transformer.resblocks.0.mlp.c_fc.bias\", \"encoder_model.visual.transformer.resblocks.0.mlp.c_proj.weight\", \"encoder_model.visual.transformer.resblocks.0.mlp.c_proj.bias\", \"encoder_model.visual.transformer.resblocks.0.ln_2.weight\", \"encoder_model.visual.transformer.resblocks.0.ln_2.bias\", \"encoder_model.visual.transformer.resblocks.1.attn.in_proj_weight\", \"encoder_model.visual.transformer.resblocks.1.attn.in_proj_bias\", \"encoder_model.visual.transformer.resblocks.1.attn.out_proj.weight\", \"encoder_model.visual.transformer.resblocks.1.attn.out_proj.bias\", \"encoder_model.visual.transformer.resblocks.1.ln_1.weight\", \"encoder_model.visual.transformer.resblocks.1.ln_...\n\tUnexpected key(s) in state_dict: \"backbone.encoder_model.positional_embedding\", \"backbone.encoder_model.text_projection\", \"backbone.encoder_model.logit_scale\", \"backbone.encoder_model.visual.class_embedding\", \"backbone.encoder_model.visual.positional_embedding\", \"backbone.encoder_model.visual.proj\", \"backbone.encoder_model.visual.conv1.weight\", \"backbone.encoder_model.visual.ln_pre.weight\", \"backbone.encoder_model.visual.ln_pre.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.attn.in_proj_bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.attn.out_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.attn.out_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.ln_1.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.ln_1.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.mlp.c_fc.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.mlp.c_fc.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.mlp.c_proj.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.mlp.c_proj.bias\", \"backbone.encoder_model.visual.transformer.resblocks.0.ln_2.weight\", \"backbone.encoder_model.visual.transformer.resblocks.0.ln_2.bias\", \"backbone.encoder_model.visual.transformer.resblocks.1.attn.in_proj_weight\", \"backbone.encoder_model.visual.transformer.resblocks.1.attn.in_proj_bias\", \"backbone.encoder_model.visual.tran..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "class SiameseNetworkWithTransformer(nn.Module):\n",
        "    def __init__(self, backbone, transformer_dim=1024, num_heads=4, num_layers=2):\n",
        "        super(SiameseNetworkWithTransformer, self).__init__()\n",
        "        self.backbone = backbone  # Use the pretrained backbone\n",
        "        self.emb_dim = backbone.classifier.out_features\n",
        "\n",
        "        # Transformer Layer\n",
        "        encoder_layer = TransformerEncoderLayer(d_model=self.emb_dim, nhead=num_heads, dim_feedforward=transformer_dim)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    def aggregate_embeddings(self, embeddings, mask):\n",
        "        # Transformer expects input shape (seq_len, batch, emb_dim), so we transpose\n",
        "        embeddings = embeddings.permute(1, 0, 2)  # (max_seq_len, batch_size, emb_dim)\n",
        "\n",
        "        # Apply transformer with mask\n",
        "        aggregated_embedding = self.transformer_encoder(embeddings, src_key_padding_mask=~mask)  # Mask is inverted\n",
        "\n",
        "        # Average pooling across the sequence dimension to get a single vector\n",
        "        aggregated_embedding = aggregated_embedding.mean(dim=0)  # (batch_size, emb_dim)\n",
        "        return aggregated_embedding\n",
        "\n",
        "    def forward(self, input1_set, input2_set, mask1, mask2):\n",
        "        \"\"\"\n",
        "        Forward pass for Siamese Network with Transformer aggregation.\n",
        "\n",
        "        Args:\n",
        "            input1_set (Tensor): Padded sequence of images from set 1 (batch_size, max_seq_len_set1, C, H, W)\n",
        "            input2_set (Tensor): Padded sequence of images from set 2 (batch_size, max_seq_len_set2, C, H, W)\n",
        "            mask1 (Tensor): Attention mask for input1_set (batch_size, max_seq_len_set1)\n",
        "            mask2 (Tensor): Attention mask for input2_set (batch_size, max_seq_len_set2)\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Aggregated embedding for input1_set (batch_size, emb_dim)\n",
        "            Tensor: Aggregated embedding for input2_set (batch_size, emb_dim)\n",
        "        \"\"\"\n",
        "        # Encode each image in the set individually using the backbone\n",
        "        embeddings1 = torch.stack([self.backbone(img) for img in input1_set])  # Shape: (batch_size, max_seq_len_set1, emb_dim)\n",
        "        embeddings2 = torch.stack([self.backbone(img) for img in input2_set])  # Shape: (batch_size, max_seq_len_set2, emb_dim)\n",
        "\n",
        "        # Aggregate embeddings using transformer with attention masks\n",
        "        aggregated_embedding1 = self.aggregate_embeddings(embeddings1, mask1)  # Shape: (batch_size, emb_dim)\n",
        "        aggregated_embedding2 = self.aggregate_embeddings(embeddings2, mask2)  # Shape: (batch_size, emb_dim)\n",
        "\n",
        "        return aggregated_embedding1, aggregated_embedding2"
      ],
      "metadata": {
        "id": "FEvH0voC9Wu1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SiameseNetworkWithTransformer(backbone=backbone, transformer_dim=1024, num_heads=4, num_layers=2).to(device)\n",
        "model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnxSnBSgIZdR",
        "outputId": "117bc0eb-a098-4b82-cf91-0652761a1e03"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "<ipython-input-16-20d0dcf03433>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E5Gg4Q-qubG",
        "outputId": "ec3f1ee2-248b-486f-a597-3a2ee62a6685"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SiameseNetworkWithTransformer(\n",
              "  (backbone): BackboneNetwork(\n",
              "    (encoder_model): CLIP(\n",
              "      (visual): VisionTransformer(\n",
              "        (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
              "        (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (transformer): Transformer(\n",
              "          (resblocks): Sequential(\n",
              "            (0): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (1): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (2): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (3): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (4): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (5): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (6): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (7): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (8): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (9): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (10): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (11): ResidualAttentionBlock(\n",
              "              (attn): MultiheadAttention(\n",
              "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): Sequential(\n",
              "                (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (gelu): QuickGELU()\n",
              "                (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (transformer): Transformer(\n",
              "        (resblocks): Sequential(\n",
              "          (0): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (1): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (2): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (3): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (4): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (5): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (6): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (7): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (8): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (9): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (10): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "          (11): ResidualAttentionBlock(\n",
              "            (attn): MultiheadAttention(\n",
              "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Sequential(\n",
              "              (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (gelu): QuickGELU()\n",
              "              (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (token_embedding): Embedding(49408, 512)\n",
              "      (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (classifier): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (transformer_encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "margin = 1\n",
        "criterion = Contrastive_loss_fn(margin=margin)\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "LJ3DLO9Hhd6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del mask1\n",
        "# del mask2\n",
        "# del input1_set\n",
        "# del input2_set\n",
        "# del model\n",
        "# del backbone\n",
        "# del output1\n",
        "# del output2\n",
        "# del loss"
      ],
      "metadata": {
        "id": "KBX-CX6tssKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set threshold for classification\n",
        "threshold = 1\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for i, (input1_set, input2_set, mask1, mask2, labels) in enumerate(train_loader):\n",
        "        # Move data to device\n",
        "        input1_set, input2_set = input1_set.to(device), input2_set.to(device)\n",
        "        mask1, mask2 = mask1.to(device), mask2.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output1, output2 = model(input1_set, input2_set, mask1, mask2)\n",
        "        del mask1, mask2, input1_set, input2_set  # Free up memory\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output1, output2, labels)\n",
        "\n",
        "        # Calculate distances for accuracy\n",
        "        with torch.no_grad():\n",
        "            distances = F.cosine_similarity(output1, output2)  # Cosine similarity\n",
        "            predictions = (distances <= threshold).float()  # Classify based on threshold\n",
        "            correct_predictions += (predictions == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "        del output1, output2, labels\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 10 == 0:  # Print every 10 batches\n",
        "            accuracy = correct_predictions / total_predictions * 100\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f} Accuracy:{accuracy:.2f}%\")\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = correct_predictions / total_predictions * 100\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"Training Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l4A0BKR2HFPj",
        "outputId": "1f916832-125b-4f4d-914b-30c2f02de926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [1/551], Loss: 0.1114 Accuracy:43.75%\n",
            "Epoch [1/10], Step [11/551], Loss: 0.1309 Accuracy:41.48%\n",
            "Epoch [1/10], Step [21/551], Loss: 0.1331 Accuracy:44.20%\n",
            "Epoch [1/10], Step [31/551], Loss: 0.1133 Accuracy:44.05%\n",
            "Epoch [1/10], Step [41/551], Loss: 0.1037 Accuracy:43.45%\n",
            "Epoch [1/10], Step [51/551], Loss: 0.0691 Accuracy:42.59%\n",
            "Epoch [1/10], Step [61/551], Loss: 0.1305 Accuracy:42.32%\n",
            "Epoch [1/10], Step [71/551], Loss: 0.1356 Accuracy:41.86%\n",
            "Epoch [1/10], Step [81/551], Loss: 0.0974 Accuracy:41.28%\n",
            "Epoch [1/10], Step [91/551], Loss: 0.1269 Accuracy:41.41%\n",
            "Epoch [1/10], Step [101/551], Loss: 0.1540 Accuracy:41.37%\n",
            "Epoch [1/10], Step [111/551], Loss: 0.1108 Accuracy:41.41%\n",
            "Epoch [1/10], Step [121/551], Loss: 0.0968 Accuracy:41.53%\n",
            "Epoch [1/10], Step [131/551], Loss: 0.1165 Accuracy:41.51%\n",
            "Epoch [1/10], Step [141/551], Loss: 0.1174 Accuracy:41.67%\n",
            "Epoch [1/10], Step [151/551], Loss: 0.0935 Accuracy:41.72%\n",
            "Epoch [1/10], Step [161/551], Loss: 0.1225 Accuracy:41.89%\n",
            "Epoch [1/10], Step [171/551], Loss: 0.1031 Accuracy:41.74%\n",
            "Epoch [1/10], Step [181/551], Loss: 0.1233 Accuracy:41.45%\n",
            "Epoch [1/10], Step [191/551], Loss: 0.0941 Accuracy:41.61%\n",
            "Epoch [1/10], Step [201/551], Loss: 0.0925 Accuracy:41.56%\n",
            "Epoch [1/10], Step [211/551], Loss: 0.0757 Accuracy:41.56%\n",
            "Epoch [1/10], Step [221/551], Loss: 0.1132 Accuracy:41.63%\n",
            "Epoch [1/10], Step [231/551], Loss: 0.0812 Accuracy:41.41%\n",
            "Epoch [1/10], Step [241/551], Loss: 0.1511 Accuracy:41.23%\n",
            "Epoch [1/10], Step [251/551], Loss: 0.1171 Accuracy:41.26%\n",
            "Epoch [1/10], Step [261/551], Loss: 0.1185 Accuracy:41.22%\n",
            "Epoch [1/10], Step [271/551], Loss: 0.1182 Accuracy:41.33%\n",
            "Epoch [1/10], Step [281/551], Loss: 0.1293 Accuracy:41.35%\n",
            "Epoch [1/10], Step [291/551], Loss: 0.0867 Accuracy:41.40%\n",
            "Epoch [1/10], Step [301/551], Loss: 0.0952 Accuracy:41.30%\n",
            "Epoch [1/10], Step [311/551], Loss: 0.0958 Accuracy:41.45%\n",
            "Epoch [1/10], Step [321/551], Loss: 0.0896 Accuracy:41.51%\n",
            "Epoch [1/10], Step [331/551], Loss: 0.1203 Accuracy:41.62%\n",
            "Epoch [1/10], Step [341/551], Loss: 0.0760 Accuracy:41.60%\n",
            "Epoch [1/10], Step [351/551], Loss: 0.0612 Accuracy:41.73%\n",
            "Epoch [1/10], Step [361/551], Loss: 0.1043 Accuracy:41.76%\n",
            "Epoch [1/10], Step [371/551], Loss: 0.0801 Accuracy:41.67%\n",
            "Epoch [1/10], Step [381/551], Loss: 0.1383 Accuracy:41.68%\n",
            "Epoch [1/10], Step [391/551], Loss: 0.0843 Accuracy:41.73%\n",
            "Epoch [1/10], Step [401/551], Loss: 0.1017 Accuracy:41.71%\n",
            "Epoch [1/10], Step [411/551], Loss: 0.1330 Accuracy:41.67%\n",
            "Epoch [1/10], Step [421/551], Loss: 0.1041 Accuracy:41.55%\n",
            "Epoch [1/10], Step [431/551], Loss: 0.1211 Accuracy:41.66%\n",
            "Epoch [1/10], Step [441/551], Loss: 0.1220 Accuracy:41.64%\n",
            "Epoch [1/10], Step [451/551], Loss: 0.1252 Accuracy:41.59%\n",
            "Epoch [1/10], Step [461/551], Loss: 0.1446 Accuracy:41.68%\n",
            "Epoch [1/10], Step [471/551], Loss: 0.1237 Accuracy:41.79%\n",
            "Epoch [1/10], Step [481/551], Loss: 0.1377 Accuracy:41.76%\n",
            "Epoch [1/10], Step [491/551], Loss: 0.1405 Accuracy:41.74%\n",
            "Epoch [1/10], Step [501/551], Loss: 0.0950 Accuracy:41.70%\n",
            "Epoch [1/10], Step [511/551], Loss: 0.1199 Accuracy:41.66%\n",
            "Epoch [1/10], Step [521/551], Loss: 0.0934 Accuracy:41.68%\n",
            "Epoch [1/10], Step [531/551], Loss: 0.1300 Accuracy:41.63%\n",
            "Epoch [1/10], Step [541/551], Loss: 0.1606 Accuracy:41.65%\n",
            "Epoch [1/10], Step [551/551], Loss: 0.0315 Accuracy:41.67%\n",
            "Epoch [1/10], Average Loss: 0.1131, Accuracy: 41.67%\n",
            "Epoch [2/10], Step [1/551], Loss: 0.0646 Accuracy:53.12%\n",
            "Epoch [2/10], Step [11/551], Loss: 0.0914 Accuracy:45.74%\n",
            "Epoch [2/10], Step [21/551], Loss: 0.0994 Accuracy:43.30%\n",
            "Epoch [2/10], Step [31/551], Loss: 0.1368 Accuracy:42.84%\n",
            "Epoch [2/10], Step [41/551], Loss: 0.1126 Accuracy:42.53%\n",
            "Epoch [2/10], Step [51/551], Loss: 0.0956 Accuracy:42.65%\n",
            "Epoch [2/10], Step [61/551], Loss: 0.1447 Accuracy:41.96%\n",
            "Epoch [2/10], Step [71/551], Loss: 0.1223 Accuracy:42.47%\n",
            "Epoch [2/10], Step [81/551], Loss: 0.1193 Accuracy:42.28%\n",
            "Epoch [2/10], Step [91/551], Loss: 0.1238 Accuracy:42.58%\n",
            "Epoch [2/10], Step [101/551], Loss: 0.0899 Accuracy:42.42%\n",
            "Epoch [2/10], Step [111/551], Loss: 0.1051 Accuracy:42.29%\n",
            "Epoch [2/10], Step [121/551], Loss: 0.1548 Accuracy:42.07%\n",
            "Epoch [2/10], Step [131/551], Loss: 0.0843 Accuracy:42.08%\n",
            "Epoch [2/10], Step [141/551], Loss: 0.1108 Accuracy:42.24%\n",
            "Epoch [2/10], Step [151/551], Loss: 0.1054 Accuracy:42.07%\n",
            "Epoch [2/10], Step [161/551], Loss: 0.0887 Accuracy:42.12%\n",
            "Epoch [2/10], Step [171/551], Loss: 0.0812 Accuracy:42.31%\n",
            "Epoch [2/10], Step [181/551], Loss: 0.1329 Accuracy:42.06%\n",
            "Epoch [2/10], Step [191/551], Loss: 0.0759 Accuracy:42.02%\n",
            "Epoch [2/10], Step [201/551], Loss: 0.1025 Accuracy:41.99%\n",
            "Epoch [2/10], Step [211/551], Loss: 0.1009 Accuracy:42.00%\n",
            "Epoch [2/10], Step [221/551], Loss: 0.0689 Accuracy:42.04%\n",
            "Epoch [2/10], Step [231/551], Loss: 0.1368 Accuracy:41.91%\n",
            "Epoch [2/10], Step [241/551], Loss: 0.0572 Accuracy:41.87%\n",
            "Epoch [2/10], Step [251/551], Loss: 0.1174 Accuracy:41.96%\n",
            "Epoch [2/10], Step [261/551], Loss: 0.0930 Accuracy:41.97%\n",
            "Epoch [2/10], Step [271/551], Loss: 0.1681 Accuracy:41.78%\n",
            "Epoch [2/10], Step [281/551], Loss: 0.1103 Accuracy:41.94%\n",
            "Epoch [2/10], Step [291/551], Loss: 0.1287 Accuracy:42.10%\n",
            "Epoch [2/10], Step [301/551], Loss: 0.1321 Accuracy:41.88%\n",
            "Epoch [2/10], Step [311/551], Loss: 0.1245 Accuracy:41.90%\n",
            "Epoch [2/10], Step [321/551], Loss: 0.1679 Accuracy:41.82%\n",
            "Epoch [2/10], Step [331/551], Loss: 0.1367 Accuracy:41.62%\n",
            "Epoch [2/10], Step [341/551], Loss: 0.0928 Accuracy:41.59%\n",
            "Epoch [2/10], Step [351/551], Loss: 0.1061 Accuracy:41.48%\n",
            "Epoch [2/10], Step [361/551], Loss: 0.1030 Accuracy:41.48%\n",
            "Epoch [2/10], Step [371/551], Loss: 0.0774 Accuracy:41.54%\n",
            "Epoch [2/10], Step [381/551], Loss: 0.0808 Accuracy:41.63%\n",
            "Epoch [2/10], Step [391/551], Loss: 0.1287 Accuracy:41.66%\n",
            "Epoch [2/10], Step [401/551], Loss: 0.0726 Accuracy:41.54%\n",
            "Epoch [2/10], Step [411/551], Loss: 0.1238 Accuracy:41.51%\n",
            "Epoch [2/10], Step [421/551], Loss: 0.1378 Accuracy:41.53%\n",
            "Epoch [2/10], Step [431/551], Loss: 0.0970 Accuracy:41.57%\n",
            "Epoch [2/10], Step [441/551], Loss: 0.1133 Accuracy:41.48%\n",
            "Epoch [2/10], Step [451/551], Loss: 0.1099 Accuracy:41.55%\n",
            "Epoch [2/10], Step [461/551], Loss: 0.1201 Accuracy:41.65%\n",
            "Epoch [2/10], Step [471/551], Loss: 0.1363 Accuracy:41.67%\n",
            "Epoch [2/10], Step [481/551], Loss: 0.1166 Accuracy:41.69%\n",
            "Epoch [2/10], Step [491/551], Loss: 0.1454 Accuracy:41.64%\n",
            "Epoch [2/10], Step [501/551], Loss: 0.0768 Accuracy:41.54%\n",
            "Epoch [2/10], Step [511/551], Loss: 0.1385 Accuracy:41.59%\n",
            "Epoch [2/10], Step [521/551], Loss: 0.0991 Accuracy:41.64%\n",
            "Epoch [2/10], Step [531/551], Loss: 0.1103 Accuracy:41.61%\n",
            "Epoch [2/10], Step [541/551], Loss: 0.1368 Accuracy:41.62%\n",
            "Epoch [2/10], Step [551/551], Loss: 0.0139 Accuracy:41.67%\n",
            "Epoch [2/10], Average Loss: 0.1131, Accuracy: 41.67%\n",
            "Epoch [3/10], Step [1/551], Loss: 0.1467 Accuracy:28.12%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-b7b3859ef652>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mmask1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2_set\u001b[0m  \u001b[0;31m# Free up memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-6ff742976699>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1_set, input2_set, mask1, mask2)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Encode each image in the set individually using the backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0membeddings1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput1_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: (batch_size, max_seq_len_set1, emb_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0membeddings2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput2_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: (batch_size, max_seq_len_set2, emb_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Aggregate embeddings using transformer with attention masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-6ff742976699>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Encode each image in the set individually using the backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0membeddings1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput1_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: (batch_size, max_seq_len_set1, emb_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0membeddings2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput2_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: (batch_size, max_seq_len_set2, emb_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Aggregate embeddings using transformer with attention masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-ccbe9f75b588>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_one_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Initialize the backbone with pretrained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-ccbe9f75b588>\u001b[0m in \u001b[0;36mencode_one_image\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_one_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clip/model.py\u001b[0m in \u001b[0;36mencode_image\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clip/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# NLD -> LND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# LND -> NLD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clip/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/clip/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     \u001b[0;31m# See full discussion on the problems with returning `Union` here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m     \u001b[0;31m# https://github.com/microsoft/pyright/issues/4213\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# storing model weights\n",
        "path=\"/content/drive/MyDrive/Projects/Minor/clip_transformer_model_parameters.pth\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "yFS8t38Ja_cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = 100  # Use 1000 tuples for validation\n",
        "train_size = len(train_data) - val_size\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_data, val_data = random_split(train_data, [train_size, val_size])\n",
        "\n",
        "# Create DataLoader for validation set\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, collate_fn=siamese_collate_fn, shuffle=False)\n",
        "len(val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D_mpyZAa19l",
        "outputId": "69b324d3-4e2d-447b-be0d-d3830393985f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def validate_model(model, val_loader, criterion, threshold):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for validation\n",
        "        for input1_set, input2_set, mask1, mask2, labels in val_loader:\n",
        "            # Move data to device\n",
        "            input1_set, input2_set = input1_set.to(device), input2_set.to(device)\n",
        "            mask1, mask2 = mask1.to(device), mask2.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output1, output2 = model(input1_set, input2_set, mask1, mask2)\n",
        "            del mask1, mask2, input1_set, input2_set  # Free up memory\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(output1, output2, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate distances and predictions based on threshold\n",
        "            distances = F.cosine_similarity(output1, output2)  # Cosine similarity\n",
        "            predictions = (distances <= threshold).float()  # Classify based on threshold\n",
        "            correct_predictions += (predictions == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "            del output1, output2, labels  # Free up memory\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate average validation loss and accuracy\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    accuracy = correct_predictions / total_predictions * 100\n",
        "\n",
        "    # print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "    return avg_val_loss, accuracy"
      ],
      "metadata": {
        "id": "EtASg_l8bMBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=1.1596283346414564\n",
        "lr=0.1\n",
        "loss_prev,acc_prev=validate_model(model, val_loader, criterion, threshold=a)\n",
        "\n",
        "print(f'threshold:{a} loss:{loss_prev}  acc:{acc_prev}')\n",
        "\n",
        "a=a+loss_prev*lr\n",
        "while True:\n",
        "  if a>2: a=2\n",
        "  if a<0: a=0\n",
        "  loss_new,acc_new=validate_model(model, val_loader, criterion, threshold=a)\n",
        "  print(f'threshold:{a} loss:{loss_new}  acc:{acc_new}')\n",
        "\n",
        "  # if abs(acc_new-acc_prev)<1e-2:\n",
        "  #   break\n",
        "  if acc_new>acc_prev:\n",
        "    a=a+loss_new*lr\n",
        "  else:\n",
        "    a=a-loss_new*lr\n",
        "\n",
        "  loss_prev,acc_prev=loss_new,acc_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "k-zPKBMabWiO",
        "outputId": "66929573-9f9a-45ea-9e63-e0d747905d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold:1.1596283346414564 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.1676329804584382 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.1596283346414564 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.1516236888244746 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.1436190430074928 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.135614397190511 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.1276097513735293 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.1196051055565475 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.1116004597395657 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.1035958139225839 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.095591168105602 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.0875865222886203 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.0795818764716385 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.0715772306546567 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.063572584837675 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.0555679390206931 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.0475632932037113 loss:0.08004645816981792  acc:46.0\n",
            "threshold:1.0395586473867295 loss:0.08004645816981792  acc:46.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-36d762c3d836>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mloss_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'threshold:{a} loss:{loss_new}  acc:{acc_new}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-7992d46dbeaf>\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(model, val_loader, criterion, threshold)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Disable gradient calculation for validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minput1_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Move data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0minput1_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput1_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-0f95b523dab5>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m           \u001b[0mimg_set1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2363\u001b[0m                 )\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m     def reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training phase 2"
      ],
      "metadata": {
        "id": "VibDn3diiegS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in backbone.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "# Set threshold for classification\n",
        "threshold = 1.0395586473867295\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for i, (input1_set, input2_set, mask1, mask2, labels) in enumerate(train_loader):\n",
        "        # Move data to device\n",
        "        input1_set, input2_set = input1_set.to(device), input2_set.to(device)\n",
        "        mask1, mask2 = mask1.to(device), mask2.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output1, output2 = model(input1_set, input2_set, mask1, mask2)\n",
        "        del mask1, mask2, input1_set, input2_set  # Free up memory\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output1, output2, labels)\n",
        "\n",
        "        # Calculate distances for accuracy\n",
        "        with torch.no_grad():\n",
        "            distances = F.cosine_similarity(output1, output2)  # Cosine similarity\n",
        "            predictions = (distances <= threshold).float()  # Classify based on threshold\n",
        "            correct_predictions += (predictions == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "        del output1, output2, labels\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 10 == 0:  # Print every 10 batches\n",
        "            accuracy = correct_predictions / total_predictions * 100\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f} Accuracy:{accuracy:.2f}%\")\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = correct_predictions / total_predictions * 100\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"Training Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkKhrIxweD7b",
        "outputId": "6e63a6fd-e5fa-4def-86b6-c926a8ad9f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [1/4401], Loss: 0.1023 Accuracy:50.00%\n",
            "Epoch [1/1], Step [11/4401], Loss: nan Accuracy:52.27%\n",
            "Epoch [1/1], Step [21/4401], Loss: nan Accuracy:61.90%\n",
            "Epoch [1/1], Step [31/4401], Loss: nan Accuracy:58.87%\n",
            "Epoch [1/1], Step [41/4401], Loss: nan Accuracy:53.66%\n",
            "Epoch [1/1], Step [51/4401], Loss: nan Accuracy:51.47%\n",
            "Epoch [1/1], Step [61/4401], Loss: nan Accuracy:52.87%\n",
            "Epoch [1/1], Step [71/4401], Loss: nan Accuracy:54.58%\n",
            "Epoch [1/1], Step [81/4401], Loss: nan Accuracy:55.56%\n",
            "Epoch [1/1], Step [91/4401], Loss: nan Accuracy:55.77%\n",
            "Epoch [1/1], Step [101/4401], Loss: nan Accuracy:54.95%\n",
            "Epoch [1/1], Step [111/4401], Loss: nan Accuracy:55.18%\n",
            "Epoch [1/1], Step [121/4401], Loss: nan Accuracy:55.58%\n",
            "Epoch [1/1], Step [131/4401], Loss: nan Accuracy:55.73%\n",
            "Epoch [1/1], Step [141/4401], Loss: nan Accuracy:56.03%\n",
            "Epoch [1/1], Step [151/4401], Loss: nan Accuracy:56.79%\n",
            "Epoch [1/1], Step [161/4401], Loss: nan Accuracy:56.06%\n",
            "Epoch [1/1], Step [171/4401], Loss: nan Accuracy:55.70%\n",
            "Epoch [1/1], Step [181/4401], Loss: nan Accuracy:55.80%\n",
            "Epoch [1/1], Step [191/4401], Loss: nan Accuracy:55.37%\n",
            "Epoch [1/1], Step [201/4401], Loss: nan Accuracy:55.22%\n",
            "Epoch [1/1], Step [211/4401], Loss: nan Accuracy:54.62%\n",
            "Epoch [1/1], Step [221/4401], Loss: nan Accuracy:54.75%\n",
            "Epoch [1/1], Step [231/4401], Loss: nan Accuracy:54.65%\n",
            "Epoch [1/1], Step [241/4401], Loss: nan Accuracy:54.88%\n",
            "Epoch [1/1], Step [251/4401], Loss: nan Accuracy:54.98%\n",
            "Epoch [1/1], Step [261/4401], Loss: nan Accuracy:55.08%\n",
            "Epoch [1/1], Step [271/4401], Loss: nan Accuracy:55.26%\n",
            "Epoch [1/1], Step [281/4401], Loss: nan Accuracy:55.07%\n",
            "Epoch [1/1], Step [291/4401], Loss: nan Accuracy:55.15%\n",
            "Epoch [1/1], Step [301/4401], Loss: nan Accuracy:54.73%\n",
            "Epoch [1/1], Step [311/4401], Loss: nan Accuracy:55.14%\n",
            "Epoch [1/1], Step [321/4401], Loss: nan Accuracy:55.22%\n",
            "Epoch [1/1], Step [331/4401], Loss: nan Accuracy:55.14%\n",
            "Epoch [1/1], Step [341/4401], Loss: nan Accuracy:55.21%\n",
            "Epoch [1/1], Step [351/4401], Loss: nan Accuracy:55.63%\n",
            "Epoch [1/1], Step [361/4401], Loss: nan Accuracy:55.61%\n",
            "Epoch [1/1], Step [371/4401], Loss: nan Accuracy:55.93%\n",
            "Epoch [1/1], Step [381/4401], Loss: nan Accuracy:56.04%\n",
            "Epoch [1/1], Step [391/4401], Loss: nan Accuracy:56.59%\n",
            "Epoch [1/1], Step [401/4401], Loss: nan Accuracy:56.42%\n",
            "Epoch [1/1], Step [411/4401], Loss: nan Accuracy:56.20%\n",
            "Epoch [1/1], Step [421/4401], Loss: nan Accuracy:56.35%\n",
            "Epoch [1/1], Step [431/4401], Loss: nan Accuracy:56.55%\n",
            "Epoch [1/1], Step [441/4401], Loss: nan Accuracy:56.86%\n",
            "Epoch [1/1], Step [451/4401], Loss: nan Accuracy:56.93%\n",
            "Epoch [1/1], Step [461/4401], Loss: nan Accuracy:57.00%\n",
            "Epoch [1/1], Step [471/4401], Loss: nan Accuracy:56.85%\n",
            "Epoch [1/1], Step [481/4401], Loss: nan Accuracy:56.70%\n",
            "Epoch [1/1], Step [491/4401], Loss: nan Accuracy:56.72%\n",
            "Epoch [1/1], Step [501/4401], Loss: nan Accuracy:56.79%\n",
            "Epoch [1/1], Step [511/4401], Loss: nan Accuracy:56.80%\n",
            "Epoch [1/1], Step [521/4401], Loss: nan Accuracy:56.91%\n",
            "Epoch [1/1], Step [531/4401], Loss: nan Accuracy:56.87%\n",
            "Epoch [1/1], Step [541/4401], Loss: nan Accuracy:56.93%\n",
            "Epoch [1/1], Step [551/4401], Loss: nan Accuracy:56.94%\n",
            "Epoch [1/1], Step [561/4401], Loss: nan Accuracy:56.95%\n",
            "Epoch [1/1], Step [571/4401], Loss: nan Accuracy:57.01%\n",
            "Epoch [1/1], Step [581/4401], Loss: nan Accuracy:57.06%\n",
            "Epoch [1/1], Step [591/4401], Loss: nan Accuracy:57.06%\n",
            "Epoch [1/1], Step [601/4401], Loss: nan Accuracy:57.24%\n",
            "Epoch [1/1], Step [611/4401], Loss: nan Accuracy:57.24%\n",
            "Epoch [1/1], Step [621/4401], Loss: nan Accuracy:57.33%\n",
            "Epoch [1/1], Step [631/4401], Loss: nan Accuracy:57.13%\n",
            "Epoch [1/1], Step [641/4401], Loss: nan Accuracy:57.29%\n",
            "Epoch [1/1], Step [651/4401], Loss: nan Accuracy:57.37%\n",
            "Epoch [1/1], Step [661/4401], Loss: nan Accuracy:57.56%\n",
            "Epoch [1/1], Step [671/4401], Loss: nan Accuracy:57.41%\n",
            "Epoch [1/1], Step [681/4401], Loss: nan Accuracy:57.31%\n",
            "Epoch [1/1], Step [691/4401], Loss: nan Accuracy:57.24%\n",
            "Epoch [1/1], Step [701/4401], Loss: nan Accuracy:57.17%\n",
            "Epoch [1/1], Step [711/4401], Loss: nan Accuracy:57.14%\n",
            "Epoch [1/1], Step [721/4401], Loss: nan Accuracy:57.18%\n",
            "Epoch [1/1], Step [731/4401], Loss: nan Accuracy:57.28%\n",
            "Epoch [1/1], Step [741/4401], Loss: nan Accuracy:57.39%\n",
            "Epoch [1/1], Step [751/4401], Loss: nan Accuracy:57.46%\n",
            "Epoch [1/1], Step [761/4401], Loss: nan Accuracy:57.42%\n",
            "Epoch [1/1], Step [771/4401], Loss: nan Accuracy:57.39%\n",
            "Epoch [1/1], Step [781/4401], Loss: nan Accuracy:57.14%\n",
            "Epoch [1/1], Step [791/4401], Loss: nan Accuracy:57.27%\n",
            "Epoch [1/1], Step [801/4401], Loss: nan Accuracy:57.30%\n",
            "Epoch [1/1], Step [811/4401], Loss: nan Accuracy:57.24%\n",
            "Epoch [1/1], Step [821/4401], Loss: nan Accuracy:57.31%\n",
            "Epoch [1/1], Step [831/4401], Loss: nan Accuracy:57.46%\n",
            "Epoch [1/1], Step [841/4401], Loss: nan Accuracy:57.28%\n",
            "Epoch [1/1], Step [851/4401], Loss: nan Accuracy:57.34%\n",
            "Epoch [1/1], Step [861/4401], Loss: nan Accuracy:57.40%\n",
            "Epoch [1/1], Step [871/4401], Loss: nan Accuracy:57.52%\n",
            "Epoch [1/1], Step [881/4401], Loss: nan Accuracy:57.38%\n",
            "Epoch [1/1], Step [891/4401], Loss: nan Accuracy:57.35%\n",
            "Epoch [1/1], Step [901/4401], Loss: nan Accuracy:57.35%\n",
            "Epoch [1/1], Step [911/4401], Loss: nan Accuracy:57.46%\n",
            "Epoch [1/1], Step [921/4401], Loss: nan Accuracy:57.41%\n",
            "Epoch [1/1], Step [931/4401], Loss: nan Accuracy:57.33%\n",
            "Epoch [1/1], Step [941/4401], Loss: nan Accuracy:57.39%\n",
            "Epoch [1/1], Step [951/4401], Loss: nan Accuracy:57.41%\n",
            "Epoch [1/1], Step [961/4401], Loss: nan Accuracy:57.39%\n",
            "Epoch [1/1], Step [971/4401], Loss: nan Accuracy:57.49%\n",
            "Epoch [1/1], Step [981/4401], Loss: nan Accuracy:57.57%\n",
            "Epoch [1/1], Step [991/4401], Loss: nan Accuracy:57.69%\n",
            "Epoch [1/1], Step [1001/4401], Loss: nan Accuracy:57.54%\n",
            "Epoch [1/1], Step [1011/4401], Loss: nan Accuracy:57.64%\n",
            "Epoch [1/1], Step [1021/4401], Loss: nan Accuracy:57.69%\n",
            "Epoch [1/1], Step [1031/4401], Loss: nan Accuracy:57.74%\n",
            "Epoch [1/1], Step [1041/4401], Loss: nan Accuracy:57.83%\n",
            "Epoch [1/1], Step [1051/4401], Loss: nan Accuracy:57.75%\n",
            "Epoch [1/1], Step [1061/4401], Loss: nan Accuracy:57.89%\n",
            "Epoch [1/1], Step [1071/4401], Loss: nan Accuracy:57.89%\n",
            "Epoch [1/1], Step [1081/4401], Loss: nan Accuracy:57.96%\n",
            "Epoch [1/1], Step [1091/4401], Loss: nan Accuracy:57.97%\n",
            "Epoch [1/1], Step [1101/4401], Loss: nan Accuracy:57.90%\n",
            "Epoch [1/1], Step [1111/4401], Loss: nan Accuracy:57.90%\n",
            "Epoch [1/1], Step [1121/4401], Loss: nan Accuracy:58.01%\n",
            "Epoch [1/1], Step [1131/4401], Loss: nan Accuracy:58.07%\n",
            "Epoch [1/1], Step [1141/4401], Loss: nan Accuracy:58.02%\n",
            "Epoch [1/1], Step [1151/4401], Loss: nan Accuracy:57.97%\n",
            "Epoch [1/1], Step [1161/4401], Loss: nan Accuracy:58.12%\n",
            "Epoch [1/1], Step [1171/4401], Loss: nan Accuracy:58.11%\n",
            "Epoch [1/1], Step [1181/4401], Loss: nan Accuracy:58.13%\n",
            "Epoch [1/1], Step [1191/4401], Loss: nan Accuracy:58.25%\n",
            "Epoch [1/1], Step [1201/4401], Loss: nan Accuracy:58.26%\n",
            "Epoch [1/1], Step [1211/4401], Loss: nan Accuracy:58.32%\n",
            "Epoch [1/1], Step [1221/4401], Loss: nan Accuracy:58.39%\n",
            "Epoch [1/1], Step [1231/4401], Loss: nan Accuracy:58.49%\n",
            "Epoch [1/1], Step [1241/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [1251/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [1261/4401], Loss: nan Accuracy:58.37%\n",
            "Epoch [1/1], Step [1271/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [1281/4401], Loss: nan Accuracy:58.43%\n",
            "Epoch [1/1], Step [1291/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [1301/4401], Loss: nan Accuracy:58.49%\n",
            "Epoch [1/1], Step [1311/4401], Loss: nan Accuracy:58.41%\n",
            "Epoch [1/1], Step [1321/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [1331/4401], Loss: nan Accuracy:58.28%\n",
            "Epoch [1/1], Step [1341/4401], Loss: nan Accuracy:58.26%\n",
            "Epoch [1/1], Step [1351/4401], Loss: nan Accuracy:58.25%\n",
            "Epoch [1/1], Step [1361/4401], Loss: nan Accuracy:58.17%\n",
            "Epoch [1/1], Step [1371/4401], Loss: nan Accuracy:58.24%\n",
            "Epoch [1/1], Step [1381/4401], Loss: nan Accuracy:58.25%\n",
            "Epoch [1/1], Step [1391/4401], Loss: nan Accuracy:58.14%\n",
            "Epoch [1/1], Step [1401/4401], Loss: nan Accuracy:58.17%\n",
            "Epoch [1/1], Step [1411/4401], Loss: nan Accuracy:58.13%\n",
            "Epoch [1/1], Step [1421/4401], Loss: nan Accuracy:58.22%\n",
            "Epoch [1/1], Step [1431/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [1441/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [1451/4401], Loss: nan Accuracy:58.27%\n",
            "Epoch [1/1], Step [1461/4401], Loss: nan Accuracy:58.30%\n",
            "Epoch [1/1], Step [1471/4401], Loss: nan Accuracy:58.24%\n",
            "Epoch [1/1], Step [1481/4401], Loss: nan Accuracy:58.25%\n",
            "Epoch [1/1], Step [1491/4401], Loss: nan Accuracy:58.17%\n",
            "Epoch [1/1], Step [1501/4401], Loss: nan Accuracy:58.18%\n",
            "Epoch [1/1], Step [1511/4401], Loss: nan Accuracy:58.19%\n",
            "Epoch [1/1], Step [1521/4401], Loss: nan Accuracy:58.14%\n",
            "Epoch [1/1], Step [1531/4401], Loss: nan Accuracy:58.25%\n",
            "Epoch [1/1], Step [1541/4401], Loss: nan Accuracy:58.24%\n",
            "Epoch [1/1], Step [1551/4401], Loss: nan Accuracy:58.17%\n",
            "Epoch [1/1], Step [1561/4401], Loss: nan Accuracy:58.18%\n",
            "Epoch [1/1], Step [1571/4401], Loss: nan Accuracy:58.21%\n",
            "Epoch [1/1], Step [1581/4401], Loss: nan Accuracy:58.21%\n",
            "Epoch [1/1], Step [1591/4401], Loss: nan Accuracy:58.08%\n",
            "Epoch [1/1], Step [1601/4401], Loss: nan Accuracy:58.12%\n",
            "Epoch [1/1], Step [1611/4401], Loss: nan Accuracy:58.10%\n",
            "Epoch [1/1], Step [1621/4401], Loss: nan Accuracy:58.16%\n",
            "Epoch [1/1], Step [1631/4401], Loss: nan Accuracy:58.23%\n",
            "Epoch [1/1], Step [1641/4401], Loss: nan Accuracy:58.21%\n",
            "Epoch [1/1], Step [1651/4401], Loss: nan Accuracy:58.21%\n",
            "Epoch [1/1], Step [1661/4401], Loss: nan Accuracy:58.23%\n",
            "Epoch [1/1], Step [1671/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [1681/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [1691/4401], Loss: nan Accuracy:58.43%\n",
            "Epoch [1/1], Step [1701/4401], Loss: nan Accuracy:58.48%\n",
            "Epoch [1/1], Step [1711/4401], Loss: nan Accuracy:58.43%\n",
            "Epoch [1/1], Step [1721/4401], Loss: nan Accuracy:58.44%\n",
            "Epoch [1/1], Step [1731/4401], Loss: nan Accuracy:58.46%\n",
            "Epoch [1/1], Step [1741/4401], Loss: nan Accuracy:58.46%\n",
            "Epoch [1/1], Step [1751/4401], Loss: nan Accuracy:58.45%\n",
            "Epoch [1/1], Step [1761/4401], Loss: nan Accuracy:58.49%\n",
            "Epoch [1/1], Step [1771/4401], Loss: nan Accuracy:58.48%\n",
            "Epoch [1/1], Step [1781/4401], Loss: nan Accuracy:58.49%\n",
            "Epoch [1/1], Step [1791/4401], Loss: nan Accuracy:58.51%\n",
            "Epoch [1/1], Step [1801/4401], Loss: nan Accuracy:58.50%\n",
            "Epoch [1/1], Step [1811/4401], Loss: nan Accuracy:58.52%\n",
            "Epoch [1/1], Step [1821/4401], Loss: nan Accuracy:58.58%\n",
            "Epoch [1/1], Step [1831/4401], Loss: nan Accuracy:58.53%\n",
            "Epoch [1/1], Step [1841/4401], Loss: nan Accuracy:58.53%\n",
            "Epoch [1/1], Step [1851/4401], Loss: nan Accuracy:58.48%\n",
            "Epoch [1/1], Step [1861/4401], Loss: nan Accuracy:58.45%\n",
            "Epoch [1/1], Step [1871/4401], Loss: nan Accuracy:58.39%\n",
            "Epoch [1/1], Step [1881/4401], Loss: nan Accuracy:58.37%\n",
            "Epoch [1/1], Step [1891/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [1901/4401], Loss: nan Accuracy:58.46%\n",
            "Epoch [1/1], Step [1911/4401], Loss: nan Accuracy:58.41%\n",
            "Epoch [1/1], Step [1921/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [1931/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [1941/4401], Loss: nan Accuracy:58.29%\n",
            "Epoch [1/1], Step [1951/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [1961/4401], Loss: nan Accuracy:58.32%\n",
            "Epoch [1/1], Step [1971/4401], Loss: nan Accuracy:58.32%\n",
            "Epoch [1/1], Step [1981/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [1991/4401], Loss: nan Accuracy:58.22%\n",
            "Epoch [1/1], Step [2001/4401], Loss: nan Accuracy:58.27%\n",
            "Epoch [1/1], Step [2011/4401], Loss: nan Accuracy:58.24%\n",
            "Epoch [1/1], Step [2021/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [2031/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [2041/4401], Loss: nan Accuracy:58.28%\n",
            "Epoch [1/1], Step [2051/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [2061/4401], Loss: nan Accuracy:58.30%\n",
            "Epoch [1/1], Step [2071/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [2081/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [2091/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [2101/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [2111/4401], Loss: nan Accuracy:58.41%\n",
            "Epoch [1/1], Step [2121/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [2131/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [2141/4401], Loss: nan Accuracy:58.29%\n",
            "Epoch [1/1], Step [2151/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [2161/4401], Loss: nan Accuracy:58.29%\n",
            "Epoch [1/1], Step [2171/4401], Loss: nan Accuracy:58.25%\n",
            "Epoch [1/1], Step [2181/4401], Loss: nan Accuracy:58.22%\n",
            "Epoch [1/1], Step [2191/4401], Loss: nan Accuracy:58.19%\n",
            "Epoch [1/1], Step [2201/4401], Loss: nan Accuracy:58.22%\n",
            "Epoch [1/1], Step [2211/4401], Loss: nan Accuracy:58.30%\n",
            "Epoch [1/1], Step [2221/4401], Loss: nan Accuracy:58.28%\n",
            "Epoch [1/1], Step [2231/4401], Loss: nan Accuracy:58.25%\n",
            "Epoch [1/1], Step [2241/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [2251/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [2261/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [2271/4401], Loss: nan Accuracy:58.39%\n",
            "Epoch [1/1], Step [2281/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [2291/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [2301/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [2311/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [2321/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [2331/4401], Loss: nan Accuracy:58.37%\n",
            "Epoch [1/1], Step [2341/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [2351/4401], Loss: nan Accuracy:58.39%\n",
            "Epoch [1/1], Step [2361/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [2371/4401], Loss: nan Accuracy:58.30%\n",
            "Epoch [1/1], Step [2381/4401], Loss: nan Accuracy:58.29%\n",
            "Epoch [1/1], Step [2391/4401], Loss: nan Accuracy:58.27%\n",
            "Epoch [1/1], Step [2401/4401], Loss: nan Accuracy:58.26%\n",
            "Epoch [1/1], Step [2411/4401], Loss: nan Accuracy:58.30%\n",
            "Epoch [1/1], Step [2421/4401], Loss: nan Accuracy:58.29%\n",
            "Epoch [1/1], Step [2431/4401], Loss: nan Accuracy:58.26%\n",
            "Epoch [1/1], Step [2441/4401], Loss: nan Accuracy:58.30%\n",
            "Epoch [1/1], Step [2451/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [2461/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [2471/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [2481/4401], Loss: nan Accuracy:58.32%\n",
            "Epoch [1/1], Step [2491/4401], Loss: nan Accuracy:58.28%\n",
            "Epoch [1/1], Step [2501/4401], Loss: nan Accuracy:58.27%\n",
            "Epoch [1/1], Step [2511/4401], Loss: nan Accuracy:58.23%\n",
            "Epoch [1/1], Step [2521/4401], Loss: nan Accuracy:58.22%\n",
            "Epoch [1/1], Step [2531/4401], Loss: nan Accuracy:58.20%\n",
            "Epoch [1/1], Step [2541/4401], Loss: nan Accuracy:58.18%\n",
            "Epoch [1/1], Step [2551/4401], Loss: nan Accuracy:58.14%\n",
            "Epoch [1/1], Step [2561/4401], Loss: nan Accuracy:58.17%\n",
            "Epoch [1/1], Step [2571/4401], Loss: nan Accuracy:58.17%\n",
            "Epoch [1/1], Step [2581/4401], Loss: nan Accuracy:58.17%\n",
            "Epoch [1/1], Step [2591/4401], Loss: nan Accuracy:58.16%\n",
            "Epoch [1/1], Step [2601/4401], Loss: nan Accuracy:58.18%\n",
            "Epoch [1/1], Step [2611/4401], Loss: nan Accuracy:58.17%\n",
            "Epoch [1/1], Step [2621/4401], Loss: nan Accuracy:58.20%\n",
            "Epoch [1/1], Step [2631/4401], Loss: nan Accuracy:58.24%\n",
            "Epoch [1/1], Step [2641/4401], Loss: nan Accuracy:58.24%\n",
            "Epoch [1/1], Step [2651/4401], Loss: nan Accuracy:58.23%\n",
            "Epoch [1/1], Step [2661/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [2671/4401], Loss: nan Accuracy:58.32%\n",
            "Epoch [1/1], Step [2681/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [2691/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [2701/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [2711/4401], Loss: nan Accuracy:58.32%\n",
            "Epoch [1/1], Step [2721/4401], Loss: nan Accuracy:58.32%\n",
            "Epoch [1/1], Step [2731/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [2741/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [2751/4401], Loss: nan Accuracy:58.32%\n",
            "Epoch [1/1], Step [2761/4401], Loss: nan Accuracy:58.30%\n",
            "Epoch [1/1], Step [2771/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [2781/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [2791/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [2801/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [2811/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [2821/4401], Loss: nan Accuracy:58.39%\n",
            "Epoch [1/1], Step [2831/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [2841/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [2851/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [2861/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [2871/4401], Loss: nan Accuracy:58.41%\n",
            "Epoch [1/1], Step [2881/4401], Loss: nan Accuracy:58.44%\n",
            "Epoch [1/1], Step [2891/4401], Loss: nan Accuracy:58.47%\n",
            "Epoch [1/1], Step [2901/4401], Loss: nan Accuracy:58.49%\n",
            "Epoch [1/1], Step [2911/4401], Loss: nan Accuracy:58.47%\n",
            "Epoch [1/1], Step [2921/4401], Loss: nan Accuracy:58.52%\n",
            "Epoch [1/1], Step [2931/4401], Loss: nan Accuracy:58.51%\n",
            "Epoch [1/1], Step [2941/4401], Loss: nan Accuracy:58.48%\n",
            "Epoch [1/1], Step [2951/4401], Loss: nan Accuracy:58.53%\n",
            "Epoch [1/1], Step [2961/4401], Loss: nan Accuracy:58.49%\n",
            "Epoch [1/1], Step [2971/4401], Loss: nan Accuracy:58.45%\n",
            "Epoch [1/1], Step [2981/4401], Loss: nan Accuracy:58.45%\n",
            "Epoch [1/1], Step [2991/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [3001/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [3011/4401], Loss: nan Accuracy:58.44%\n",
            "Epoch [1/1], Step [3021/4401], Loss: nan Accuracy:58.47%\n",
            "Epoch [1/1], Step [3031/4401], Loss: nan Accuracy:58.46%\n",
            "Epoch [1/1], Step [3041/4401], Loss: nan Accuracy:58.50%\n",
            "Epoch [1/1], Step [3051/4401], Loss: nan Accuracy:58.47%\n",
            "Epoch [1/1], Step [3061/4401], Loss: nan Accuracy:58.44%\n",
            "Epoch [1/1], Step [3071/4401], Loss: nan Accuracy:58.46%\n",
            "Epoch [1/1], Step [3081/4401], Loss: nan Accuracy:58.44%\n",
            "Epoch [1/1], Step [3091/4401], Loss: nan Accuracy:58.41%\n",
            "Epoch [1/1], Step [3101/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [3111/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3121/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [3131/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [3141/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [3151/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [3161/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3171/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [3181/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [3191/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [3201/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [3211/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3221/4401], Loss: nan Accuracy:58.39%\n",
            "Epoch [1/1], Step [3231/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [3241/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3251/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [3261/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3271/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3281/4401], Loss: nan Accuracy:58.39%\n",
            "Epoch [1/1], Step [3291/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [3301/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3311/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [3321/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [3331/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [3341/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [3351/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [3361/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [3371/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [3381/4401], Loss: nan Accuracy:58.39%\n",
            "Epoch [1/1], Step [3391/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3401/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [3411/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [3421/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [3431/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3441/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [3451/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3461/4401], Loss: nan Accuracy:58.39%\n",
            "Epoch [1/1], Step [3471/4401], Loss: nan Accuracy:58.41%\n",
            "Epoch [1/1], Step [3481/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [3491/4401], Loss: nan Accuracy:58.37%\n",
            "Epoch [1/1], Step [3501/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [3511/4401], Loss: nan Accuracy:58.41%\n",
            "Epoch [1/1], Step [3521/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [3531/4401], Loss: nan Accuracy:58.40%\n",
            "Epoch [1/1], Step [3541/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [3551/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [3561/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [3571/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [3581/4401], Loss: nan Accuracy:58.45%\n",
            "Epoch [1/1], Step [3591/4401], Loss: nan Accuracy:58.49%\n",
            "Epoch [1/1], Step [3601/4401], Loss: nan Accuracy:58.50%\n",
            "Epoch [1/1], Step [3611/4401], Loss: nan Accuracy:58.51%\n",
            "Epoch [1/1], Step [3621/4401], Loss: nan Accuracy:58.52%\n",
            "Epoch [1/1], Step [3631/4401], Loss: nan Accuracy:58.53%\n",
            "Epoch [1/1], Step [3641/4401], Loss: nan Accuracy:58.53%\n",
            "Epoch [1/1], Step [3651/4401], Loss: nan Accuracy:58.53%\n",
            "Epoch [1/1], Step [3661/4401], Loss: nan Accuracy:58.54%\n",
            "Epoch [1/1], Step [3671/4401], Loss: nan Accuracy:58.54%\n",
            "Epoch [1/1], Step [3681/4401], Loss: nan Accuracy:58.55%\n",
            "Epoch [1/1], Step [3691/4401], Loss: nan Accuracy:58.57%\n",
            "Epoch [1/1], Step [3701/4401], Loss: nan Accuracy:58.58%\n",
            "Epoch [1/1], Step [3711/4401], Loss: nan Accuracy:58.55%\n",
            "Epoch [1/1], Step [3721/4401], Loss: nan Accuracy:58.55%\n",
            "Epoch [1/1], Step [3731/4401], Loss: nan Accuracy:58.57%\n",
            "Epoch [1/1], Step [3741/4401], Loss: nan Accuracy:58.55%\n",
            "Epoch [1/1], Step [3751/4401], Loss: nan Accuracy:58.56%\n",
            "Epoch [1/1], Step [3761/4401], Loss: nan Accuracy:58.54%\n",
            "Epoch [1/1], Step [3771/4401], Loss: nan Accuracy:58.55%\n",
            "Epoch [1/1], Step [3781/4401], Loss: nan Accuracy:58.54%\n",
            "Epoch [1/1], Step [3791/4401], Loss: nan Accuracy:58.55%\n",
            "Epoch [1/1], Step [3801/4401], Loss: nan Accuracy:58.56%\n",
            "Epoch [1/1], Step [3811/4401], Loss: nan Accuracy:58.53%\n",
            "Epoch [1/1], Step [3821/4401], Loss: nan Accuracy:58.54%\n",
            "Epoch [1/1], Step [3831/4401], Loss: nan Accuracy:58.56%\n",
            "Epoch [1/1], Step [3841/4401], Loss: nan Accuracy:58.57%\n",
            "Epoch [1/1], Step [3851/4401], Loss: nan Accuracy:58.59%\n",
            "Epoch [1/1], Step [3861/4401], Loss: nan Accuracy:58.57%\n",
            "Epoch [1/1], Step [3871/4401], Loss: nan Accuracy:58.56%\n",
            "Epoch [1/1], Step [3881/4401], Loss: nan Accuracy:58.59%\n",
            "Epoch [1/1], Step [3891/4401], Loss: nan Accuracy:58.60%\n",
            "Epoch [1/1], Step [3901/4401], Loss: nan Accuracy:58.61%\n",
            "Epoch [1/1], Step [3911/4401], Loss: nan Accuracy:58.57%\n",
            "Epoch [1/1], Step [3921/4401], Loss: nan Accuracy:58.56%\n",
            "Epoch [1/1], Step [3931/4401], Loss: nan Accuracy:58.56%\n",
            "Epoch [1/1], Step [3941/4401], Loss: nan Accuracy:58.56%\n",
            "Epoch [1/1], Step [3951/4401], Loss: nan Accuracy:58.52%\n",
            "Epoch [1/1], Step [3961/4401], Loss: nan Accuracy:58.49%\n",
            "Epoch [1/1], Step [3971/4401], Loss: nan Accuracy:58.46%\n",
            "Epoch [1/1], Step [3981/4401], Loss: nan Accuracy:58.46%\n",
            "Epoch [1/1], Step [3991/4401], Loss: nan Accuracy:58.47%\n",
            "Epoch [1/1], Step [4001/4401], Loss: nan Accuracy:58.44%\n",
            "Epoch [1/1], Step [4011/4401], Loss: nan Accuracy:58.45%\n",
            "Epoch [1/1], Step [4021/4401], Loss: nan Accuracy:58.44%\n",
            "Epoch [1/1], Step [4031/4401], Loss: nan Accuracy:58.46%\n",
            "Epoch [1/1], Step [4041/4401], Loss: nan Accuracy:58.44%\n",
            "Epoch [1/1], Step [4051/4401], Loss: nan Accuracy:58.45%\n",
            "Epoch [1/1], Step [4061/4401], Loss: nan Accuracy:58.43%\n",
            "Epoch [1/1], Step [4071/4401], Loss: nan Accuracy:58.41%\n",
            "Epoch [1/1], Step [4081/4401], Loss: nan Accuracy:58.42%\n",
            "Epoch [1/1], Step [4091/4401], Loss: nan Accuracy:58.38%\n",
            "Epoch [1/1], Step [4101/4401], Loss: nan Accuracy:58.37%\n",
            "Epoch [1/1], Step [4111/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [4121/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [4131/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [4141/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [4151/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [4161/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [4171/4401], Loss: nan Accuracy:58.30%\n",
            "Epoch [1/1], Step [4181/4401], Loss: nan Accuracy:58.30%\n",
            "Epoch [1/1], Step [4191/4401], Loss: nan Accuracy:58.31%\n",
            "Epoch [1/1], Step [4201/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [4211/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [4221/4401], Loss: nan Accuracy:58.37%\n",
            "Epoch [1/1], Step [4231/4401], Loss: nan Accuracy:58.37%\n",
            "Epoch [1/1], Step [4241/4401], Loss: nan Accuracy:58.37%\n",
            "Epoch [1/1], Step [4251/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [4261/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [4271/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [4281/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [4291/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [4301/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [4311/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [4321/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [4331/4401], Loss: nan Accuracy:58.36%\n",
            "Epoch [1/1], Step [4341/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [4351/4401], Loss: nan Accuracy:58.34%\n",
            "Epoch [1/1], Step [4361/4401], Loss: nan Accuracy:58.32%\n",
            "Epoch [1/1], Step [4371/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Step [4381/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [4391/4401], Loss: nan Accuracy:58.35%\n",
            "Epoch [1/1], Step [4401/4401], Loss: nan Accuracy:58.33%\n",
            "Epoch [1/1], Average Loss: nan, Accuracy: 58.33%\n",
            "Training Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKf5H0epD0rq",
        "outputId": "0686496f-78a2-4ea9-9e3c-80885e072726"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.5.1+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4132 sha256=5d590ef90a8aff1b36cbbdad98b757149ccb271770623c72b8117e0aa37bb4da\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "# batch = next(iter(train_loader))\n",
        "# yhat = model(batch[0], batch[1], batch[2], batch[3])\n",
        "# print(yhat\n",
        "\n",
        "\n",
        "\n",
        "for i, (input1_set, input2_set, mask1, mask2, labels) in enumerate(train_loader):\n",
        "        # Move data to device\n",
        "        input1_set, input2_set = input1_set.to(device), input2_set.to(device)\n",
        "        mask1, mask2 = mask1.to(device), mask2.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        yhat = model(input1_set, input2_set, mask1, mask2)\n",
        "        break\n",
        "\n",
        "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CcflplfwDyUO",
        "outputId": "31c2ca64-dcad-49fc-c416-4c127e15d3e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.825448 to fit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rnn_torchviz.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}